<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=description content="A Material Design theme for MkDocs"><link rel=canonical href="https://squidfunk.github.io/mkdocs-material/Naive Bayes/"><meta name=author content="Martin Donath"><meta name=lang:clipboard.copy content="Copy to clipboard"><meta name=lang:clipboard.copied content="Copied to clipboard"><meta name=lang:search.language content=en><meta name=lang:search.pipeline.stopwords content=True><meta name=lang:search.pipeline.trimmer content=True><meta name=lang:search.result.none content="No matching documents"><meta name=lang:search.result.one content="1 matching document"><meta name=lang:search.result.other content="# matching documents"><meta name=lang:search.tokenizer content=[\s\-]+><link rel="shortcut icon" href=../assets/images/favicon.png><meta name=generator content="mkdocs-1.0.4, mkdocs-material-4.4.2"><title>Naive Bayes - Material for MkDocs</title><link rel=stylesheet href=../assets/stylesheets/application.4031d38b.css><link rel=stylesheet href=../assets/stylesheets/application-palette.3e3d1dff.css><meta name=theme-color content=#3f51b5><script src=../assets/javascripts/modernizr.74668098.js></script><link href=https://fonts.gstatic.com rel=preconnect crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono&display=fallback"><style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style><link rel=stylesheet href=../assets/fonts/material-icons.css><script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "None", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script><script async src=https://www.google-analytics.com/analytics.js></script></head> <body dir=ltr data-md-color-primary=indigo data-md-color-accent=indigo> <svg class=md-svg> <defs> <svg xmlns=http://www.w3.org/2000/svg width=416 height=448 viewbox="0 0 416 448" id=__github><path fill=currentColor d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg> </defs> </svg> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay data-md-component=overlay for=__drawer></label> <a href=#naive-bayes tabindex=1 class=md-skip> Skip to content </a> <header class=md-header data-md-component=header> <nav class="md-header-nav md-grid"> <div class=md-flex> <div class="md-flex__cell md-flex__cell--shrink"> <a href=https://squidfunk.github.io/mkdocs-material/ title="Material for MkDocs" class="md-header-nav__button md-logo"> <i class=md-icon></i> </a> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--menu md-header-nav__button" for=__drawer></label> </div> <div class="md-flex__cell md-flex__cell--stretch"> <div class="md-flex__ellipsis md-header-nav__title" data-md-component=title> <span class=md-header-nav__topic> Material for MkDocs </span> <span class=md-header-nav__topic> Naive Bayes </span> </div> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--search md-header-nav__button" for=__search></label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=query data-md-state=active> <label class="md-icon md-search__icon" for=__search></label> <button type=reset class="md-icon md-search__icon" data-md-component=reset tabindex=-1> &#xE5CD; </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=result> <div class=md-search-result__meta> Type to start searching </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> </div> <div class="md-flex__cell md-flex__cell--shrink"> <div class=md-header-nav__source> <a href=https://github.com/squidfunk/mkdocs-material title="Go to repository" class=md-source data-md-source=github> <div class=md-source__icon> <svg viewbox="0 0 24 24" width=24 height=24> <use xlink:href=#__github width=24 height=24></use> </svg> </div> <div class=md-source__repository> squidfunk/mkdocs-material </div> </a> </div> </div> </div> </nav> </header> <div class=md-container> <nav class=md-tabs data-md-component=tabs> <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=.. class="md-tabs__link md-tabs__link--active"> Material </a> </li> <li class=md-tabs__item> <a href=../extensions/admonition/ class=md-tabs__link> Extensions </a> </li> </ul> </div> </nav> <main class=md-main role=main> <div class="md-main__inner md-grid" data-md-component=container> <div class="md-sidebar md-sidebar--primary" data-md-component=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" data-md-level=0> <label class="md-nav__title md-nav__title--site" for=__drawer> <a href=https://squidfunk.github.io/mkdocs-material/ title="Material for MkDocs" class="md-nav__button md-logo"> <i class=md-icon></i> </a> Material for MkDocs </label> <div class=md-nav__source> <a href=https://github.com/squidfunk/mkdocs-material title="Go to repository" class=md-source data-md-source=github> <div class=md-source__icon> <svg viewbox="0 0 24 24" width=24 height=24> <use xlink:href=#__github width=24 height=24></use> </svg> </div> <div class=md-source__repository> squidfunk/mkdocs-material </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=.. title=Material class=md-nav__link> Material </a> </li> <li class=md-nav__item> <a href=../getting-started/ title="Getting started" class=md-nav__link> Getting started </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-toggle md-nav__toggle" data-md-toggle=nav-3 type=checkbox id=nav-3> <label class=md-nav__link for=nav-3> Extensions </label> <nav class=md-nav data-md-component=collapsible data-md-level=1> <label class=md-nav__title for=nav-3> Extensions </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../extensions/admonition/ title=Admonition class=md-nav__link> Admonition </a> </li> <li class=md-nav__item> <a href=../extensions/codehilite/ title=CodeHilite class=md-nav__link> CodeHilite </a> </li> <li class=md-nav__item> <a href=../extensions/footnotes/ title=Footnotes class=md-nav__link> Footnotes </a> </li> <li class=md-nav__item> <a href=../extensions/metadata/ title=Metadata class=md-nav__link> Metadata </a> </li> <li class=md-nav__item> <a href=../extensions/permalinks/ title=Permalinks class=md-nav__link> Permalinks </a> </li> <li class=md-nav__item> <a href=../extensions/pymdown/ title=PyMdown class=md-nav__link> PyMdown </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../specimen/ title=Specimen class=md-nav__link> Specimen </a> </li> <li class=md-nav__item> <a href=../customization/ title=Customization class=md-nav__link> Customization </a> </li> <li class=md-nav__item> <a href=../compliance/ title="Compliance with GDPR" class=md-nav__link> Compliance with GDPR </a> </li> <li class=md-nav__item> <a href=../release-notes/ title="Release notes" class=md-nav__link> Release notes </a> </li> <li class=md-nav__item> <a href=../authors-notes/ title="Author's notes" class=md-nav__link> Author's notes </a> </li> <li class=md-nav__item> <a href=../contributing/ title=Contributing class=md-nav__link> Contributing </a> </li> <li class=md-nav__item> <a href=../license/ title=License class=md-nav__link> License </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary"> <label class=md-nav__title for=__toc>Table of contents</label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#1-kelebihan-kekurangan-naive-bayes class=md-nav__link> 1. Kelebihan &amp; Kekurangan Naive Bayes </a> </li> <li class=md-nav__item> <a href=#2-persamaan-teorema-bayes class=md-nav__link> 2. Persamaan Teorema Bayes </a> </li> <li class=md-nav__item> <a href=#3-laplace-correction class=md-nav__link> 3. Laplace Correction </a> </li> <li class=md-nav__item> <a href=#4-contoh-perhitungan-naive-bayes-1 class=md-nav__link> 4. Contoh Perhitungan Naive Bayes (1) </a> </li> <li class=md-nav__item> <a href=#5-contoh-perhitungan-naive-bayes-2 class=md-nav__link> **5. Contoh Perhitungan Naive Bayes (2) ** </a> </li> <li class=md-nav__item> <a href=#6-contoh-perhitungan-naive-bayes-3 class=md-nav__link> 6. Contoh Perhitungan Naive Bayes (3) </a> </li> <li class=md-nav__item> <a href=#7-contoh-perhitungan-naive-bayes-4 class=md-nav__link> 7. Contoh Perhitungan Naive Bayes (4) </a> </li> <li class=md-nav__item> <a href=#tugas-naive-bayes-menggunakan-data-iris-bunga class=md-nav__link> Tugas naive bayes menggunakan data iris bunga </a> </li> <li class=md-nav__item> <a href=#membaca-data class=md-nav__link> Membaca data </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content> <article class="md-content__inner md-typeset"> <h1 id=naive-bayes>Naive Bayes<a class=headerlink href=#naive-bayes title="Permanent link">&para;</a></h1> <p><strong>Algoritma Naive Bayes</strong> merupakan sebuah metoda klasifikasi menggunakan metode probabilitas dan statistik yg dikemukakan oleh ilmuwan Inggris Thomas Bayes. <strong>Algoritma Naive Bayes</strong> memprediksi peluang di masa depan berdasarkan pengalaman di masa sebelumnya sehingga dikenal sebagai Teorema Bayes. Ciri utama dr Naïve Bayes Classifier ini adalah asumsi yg sangat kuat (naïf) akan independensi dari masing-masing kondisi / kejadian</p> <p>Naive Bayes Classifier bekerja sangat baik dibanding dengan model classifier lainnya. Hal ini dibuktikan pada jurnal *Xhemali, Daniela, Chris J. Hinde, and Roger G. Stone. “Naive Bayes vs. decision trees vs. neural networks in the classification of training web pages.” (2009), *mengatakan bahwa “Naïve Bayes Classifier memiliki tingkat akurasi yg lebih baik dibanding model classifier lainnya”.</p> <p>Keuntungan penggunan adalah bahwa metoda ini hanya membutuhkan jumlah data pelatihan (training data) yang kecil untuk menentukan estimasi parameter yg diperlukan dalam proses pengklasifikasian. Karena yg diasumsikan sebagai variabel independent, maka hanya varians dari suatu variabel dalam sebuah kelas yang dibutuhkan untuk menentukan klasifikasi, bukan keseluruhan dari matriks kovarians.</p> <p>Tahapan dari proses algoritma Naive Bayes adalah:</p> <ol> <li>Menghitung jumlah kelas / label.</li> <li>Menghitung Jumlah Kasus Per Kelas</li> <li>Kalikan Semua Variable Kelas</li> <li>Bandingkan Hasil Per Kelas</li> </ol> <h4 id=1-kelebihan-kekurangan-naive-bayes><strong>1. Kelebihan &amp; Kekurangan Naive Bayes</strong><a class=headerlink href=#1-kelebihan-kekurangan-naive-bayes title="Permanent link">&para;</a></h4> <p><strong>Kelebihan</strong></p> <ul> <li>Mudah untuk dibuat</li> <li>Hasil bagus</li> </ul> <p><strong>Kekurangan</strong></p> <ul> <li>Asumsi independence antar atribut membuat akurasi berkurang (karena biasanya ada keterkaitan)</li> </ul> <h4 id=2-persamaan-teorema-bayes><strong>2. Persamaan Teorema Bayes</strong><a class=headerlink href=#2-persamaan-teorema-bayes title="Permanent link">&para;</a></h4> <p>contoh perhitungan bayes</p> <p>rumus bayes (1)</p> <p><img alt="contoh perhitungan bayes" src=https://informatikalogi.com/wp-content/uploads/2017/04/naive-bayes-table.jpg></p> <p><strong>Keterangan :</strong> <strong>*x*</strong> : Data dengan class yang belum diketahui <strong>*c*</strong> : Hipotesis data merupakan suatu class spesifik <strong>*P(c|x)*</strong> : Probabilitas hipotesis berdasar kondisi (posteriori probability) <strong>*P&copy;*</strong> : Probabilitas hipotesis (prior probability) <strong>*P(x|c)*</strong> : Probabilitas berdasarkan kondisi pada hipotesis <strong>*P(x)*</strong> : Probabilitas c</p> <p><a href=https://informatikalogi.com/ekstraksi-rules-pada-decision-tree/ ></a></p> <p><img alt="naive bayes formula" src=https://informatikalogi.com/wp-content/uploads/2017/04/naive-bayes-formula-1-1.jpg></p> <p>Rumus diatas menjelaskan bahwa peluang masuknya sampel karakteristik tertentu dalam kelas C (Posterior) adalah peluang munculnya kelas C (sebelum masuknya sampel tersebut, seringkali disebut prior), dikali dengan peluang kemunculan karakteristik karakteristik sampel pada kelas C (disebut juga likelihood), dibagi dengan peluang kemunculan karakteristik sampel secara global ( disebut juga evidence). Karena itu, rumus diatas dapat pula ditulis sebagai berikut :</p> <p><img alt="rumus bayes (2)" src=https://informatikalogi.com/wp-content/uploads/2017/04/naive-bayes-formula-3.jpg></p> <p>Nilai Evidence selalu tetap untuk setiap kelas pada satu sampel. Nilai dari posterior tersebut nantinya akan dibandingkan dengan nilai nilai posterior kelas lainnya untuk menentukan ke kelas apa suatu sampel akan diklasifikasikan. Penjabaran lebih lanjut rumus Bayes tersebut dilakukan dengan menjabarkan <em>(c|x1,…,xn)</em> menggunakan aturan perkalian sebagai berikut :</p> <p>rumus bayes (3)</p> <p>Dapat dilihat bahwa hasil penjabaran tersebut menyebabkan semakin banyak dan semakin kompleksnya faktor faktor syarat yang mempengaruhi nilai probabilitas, yang hampir mustahil untuk dianalisa satu persatu. Akibatnya, perhitungan tersebut menjadi sulit untuk dilakukan. Disinilah digunakan asumsi independensi yang sangat tinggi (naif), bahwa masing masing petunjuk saling bebas (independen) satu sama lain. Dengan asumsi tersebut, maka berlaku suatu kesamaan sebagai berikut:</p> <p><img alt="rumus bayes (3)" src=https://informatikalogi.com/wp-content/uploads/2017/04/naive-bayes-formula-4.jpg></p> <p><img alt="rumus bayes (5)" src=https://informatikalogi.com/wp-content/uploads/2017/04/naive-bayes-formula-2-3.jpg></p> <p>Persamaan diatas merupakan model dari <strong>Teorema Naive Bayes</strong> yang selanjutnya akan digunakan dalam proses klasifikasi. Untuk klasifikasi dengan data kontinyu digunakan rumus Densitas Gauss :</p> <p><img alt="distribusi normal gauss" src=https://informatikalogi.com/wp-content/uploads/2017/04/distribusi-normal-gauss.jpg></p> <p><strong>Keterangan :</strong> <strong>*P*</strong> : Peluang <strong>*Xi*</strong> : Atribut ke i <strong>*xi*</strong> : Nilai atribut ke i <strong>*Y*</strong> : Kelas yang dicari <strong>*yj*</strong> : Sub kelas Y yang dicari <strong>*u*</strong> : Mean, menyatakan rata rata dari seluruh atribut <strong>*o*</strong> : Deviasi standar, menyatakan varian dari seluruh atribut</p> <p><strong>Mean</strong></p> <p><img alt=mean src=https://informatikalogi.com/wp-content/uploads/2017/04/mean-formula.jpg></p> <p><strong>Deviasi Standar</strong></p> <p><img alt="standart deviasi" src=https://informatikalogi.com/wp-content/uploads/2017/04/standart-deviasi-formula.jpg></p> <h4 id=3-laplace-correction><strong>3. Laplace Correction</strong><a class=headerlink href=#3-laplace-correction title="Permanent link">&para;</a></h4> <p><strong>Laplace Correction (Laplacian Estimator)</strong> atau <strong>additive smoothing</strong> adalah suatu cara untuk menangani nilai probabilitas 0 (nol). Dari sekian banyak data di training set, pada setiap perhitungan datanya ditambah 1 (satu) dan tidak akan membuat perbedaan yang berarti pada estimasi probabilitas sehingga bisa menghindari kasus nilai probabilitas 0 (nol).</p> <p><img alt="laplace smoothing" src=https://informatikalogi.com/wp-content/uploads/2017/04/laplace-smoothing.jpg></p> <p>dimana nilai <em>k</em> adalah jumlah kelas atau bin dari atribut <em>mi</em>.</p> <p><a href=https://informatikalogi.com/klasifikasi-teks-menggunakan-k-nn/ ></a></p> <p>Sebagai contoh, asumsikan ada class buy=yes di suatu training set, memiliki 1000 (seribu ) sampel, ada 0 (nol) sampel dengan <em>income=low</em>, 990 sampel dengan <em>income=medium</em>, dan 10 sampel dengan <em>income=high</em>.</p> <p>Probabilitas dari kejadian ini tanpa Laplacian Correction adalah 0, 0.990 (dari 990/1000), dan 0.010 (dari 10/1000). Menggunakan Laplacian Correction dari tiga sampel diatas, diasumsikan ada 1 sampel lagi untuk masing – masing nilai income. Dengan cara ini, didapatkanlah probabilitas sebagai berikut (dibulatkan menjadi 3 angka dibelakang koma):</p> <p>1/1003 = <strong>0.001</strong> | 991/1003 = <strong>0.988</strong> | 11/1003 = <strong>0.011</strong></p> <p>Probabilitas yang “dibenarkan” hasilnya tidak berbeda jauh dengan hasil probabilitas sebelumnya sehingga nilai probabilitas 0 (nol) dapat dihindari.</p> <h4 id=4-contoh-perhitungan-naive-bayes-1><strong>4. Contoh Perhitungan Naive Bayes (1)</strong><a class=headerlink href=#4-contoh-perhitungan-naive-bayes-1 title="Permanent link">&para;</a></h4> <p><img alt="Contoh 1 Algoritma Naive Bayes" src=https://informatikalogi.com/wp-content/uploads/2017/04/contoh-1-algoritma-naive-bayes.jpg></p> <p><strong>Data Testing : X</strong> = (<strong>age</strong> &lt;= 30, <strong>income</strong> = medium, <strong>student</strong> = yes, <strong>credit_rating</strong> = fair)</p> <p><strong>P(Ci)</strong> P(buys_computer = “yes”) = 9/14 = 0.643 P(buys_computer = “no”) = 5/14 = 0.357</p> <p>**P(X|Ci)**P(Age = “&lt;=30” | buys_computer = “yes”) = 2/9 = 0.222 P(Age = “&lt;=30” | buys_computer = “no”) = &#8535; = 0.6 P(Income = “medium” | buys_computer = “yes”) = 4/9 = 0.444 P(Income = “medium” | buys_computer = “no”) = &#8534; = 0.4 P(student = “yes” | buys_computer = “yes”) = 6/9 = 0.667 P(student = “yes” | buys_computer = “no”) = &#8533; = 0.2 P(credit_rating = “fair” | buys_computer = “yes”) = 6/9 = 0.667 P(credit_rating = “fair” | buys_computer = “no”) = &#8534; = 0.4</p> <p>P(X|buys_computer = “yes”) = 0.222 x 0.444 x 0.667 x 0.667 = 0.044 P(X|buys_computer = “no”) = 0.6 x 0.4 x 0.2 x 0.4 = 0.019</p> <p><strong>P(X|Ci)*P(Ci)</strong> P(X|buys_computer = “yes”)<em>P(buys_computer = “yes”) = **0.028*</em> P(X|buys_computer = “no”)*P(buys_computer = “no”) = 0.007</p> <p>Untuk <strong>age</strong> = “&lt;=30”, <strong>income</strong> = “medium”, <strong>student</strong> = “yes”, <strong>credit_rating</strong> = “fair”, masuk ke kelas <strong>buys_computer</strong> = “yes”</p> <h4 id=5-contoh-perhitungan-naive-bayes-2>**5. Contoh Perhitungan Naive Bayes (2) **<a class=headerlink href=#5-contoh-perhitungan-naive-bayes-2 title="Permanent link">&para;</a></h4> <p><img alt="Contoh 1 Algoritma Naive Bayes" src=https://informatikalogi.com/wp-content/uploads/2017/04/contoh-1-algoritma-naive-bayes.jpg></p> <p><strong>Data Testing :</strong></p> <p><img alt="Data Testing Contoh 2 Naive Bayes" src=https://informatikalogi.com/wp-content/uploads/2017/04/data-testing-contoh-2-naive-bayes.jpg></p> <p>**P(Ci)**P(STATUS KELULUSAN = “TEPAT”) = 8/15 P(STATUS KELULUSAN = “TERLAMBAT”) = 7/15</p> <p>**P(X|Ci)**P(JENIS KELAMIN = “LAKI – LAKI” | STATUS KELULUSAN = “TEPAT”) = &#8541; P(JENIS KELAMIN = “LAKI – LAKI” | STATUS KELULUSAN = “TERLAMBAT”) = 3/7 P(STATUS MAHASISWA = “MAHASISWA” | STATUS KELULUSAN = “TEPAT”) = &#8541; P(STATUS MAHASISWA = “MAHASISWA” | STATUS KELULUSAN = “TERLAMBAT”) = 3/7 P(STATUS PRENIKAHAN = “BELUM” | STATUS KELULUSAN = “TEPAT”) = 4/8 P(STATUS PRENIKAHAN = “BELUM” | STATUS KELULUSAN = “TERLAMBAT”) = 4/7 P(IPK = “2.70” | STATUS KELULUSAN = “TEPAT”) = 0/8 P(IPK = “2.70” | STATUS KELULUSAN = “TERLAMBAT”) = 1/7</p> <p><a href=https://informatikalogi.com/contoh-clustering-text-menggunakan-agglomerative-hierarchical-clustering-ahc/ >Baca Juga : Contoh Clustering Text Menggunakan Agglomerative Hierarchical Clustering (AHC)</a></p> <p>P(X|<strong>STATUS KELULUSAN</strong> = “TEPAT”) = P(<strong>KELAMIN</strong> = “LAKI – LAKI”, <strong>STATUS MAHASISWA</strong> = “MAHASISWA”, <strong>STATUS PERNIKAHAN</strong> = “BELUM”, <strong>IPK</strong> = 2.70 | <strong>STATUS KELULUSAN</strong> = “TEPAT”) = &#8541; * &#8541; * 4/8 &amp; 0/8 = 0 P(X|<strong>STATUS KELULUSAN</strong> = “TERLAMBAT”) = P(<strong>KELAMIN</strong> = “LAKI – LAKI”, <strong>STATUS MAHASISWA</strong> = “MAHASISWA”, <strong>STATUS PERNIKAHAN</strong> = “BELUM”, <strong>IPK</strong> = 2.70 | <strong>STATUS KELULUSAN</strong> = “TERLAMBAT”) = 3/7 * 3/7 * 4/7 * 1/7 = 0.43 * 0.43 * 0.57 * 0.14 = 0,014</p> <p><strong>P(X|Ci)*P(Ci)**P(X|**STATUS KELULUSAN</strong> = “TEPAT”)<em>P(**STATUS KELULUSAN*</em> = “TEPAT”) = 0 * 8/15 = 0 P(X|<strong>STATUS KELULUSAN</strong> = “TERLAMBAT”)<em>P(**STATUS KELULUSAN*</em> = “TERLAMBAT”) = 0.014 * 7/15 = <strong>0.0069</strong></p> <p>Untuk <strong>KELAMIN</strong> = “LAKI – LAKI”, <strong>STATUS MAHASISWA</strong> = “MAHASISWA”, <strong>STATUS PERNIKAHAN</strong> = “BELUM”, <strong>IPK</strong> = 2.70, masuk ke kelas <strong>STATUS KELULUSAN</strong> = “TERLAMBAT”</p> <h4 id=6-contoh-perhitungan-naive-bayes-3><strong>6. Contoh Perhitungan Naive Bayes (3)</strong><a class=headerlink href=#6-contoh-perhitungan-naive-bayes-3 title="Permanent link">&para;</a></h4> <p><img alt="bilangan continue naive bayes" src=https://informatikalogi.com/wp-content/uploads/2017/04/standart-deviasi-naive-bayes.jpg></p> <h4 id=7-contoh-perhitungan-naive-bayes-4><strong>7. Contoh Perhitungan Naive Bayes (4)</strong><a class=headerlink href=#7-contoh-perhitungan-naive-bayes-4 title="Permanent link">&para;</a></h4> <p><img alt="contoh dataset rumus bayes" src=https://informatikalogi.com/wp-content/uploads/2017/04/contoh-kasus-4-naive-bayes.jpg></p> <p>karena data berupa bilangan kardinal, maka perlu adanya pemodelan ulang bentuk data tersebut dengan mencari nilai <strong>mean</strong> dan <strong>standart deviasi.</strong></p> <p><img alt="hasil pencarian standar deviasi dan mean" src=https://informatikalogi.com/wp-content/uploads/2017/04/contoh-kasus-4-naive-bayes-2.jpg></p> <p><strong>Data Testing</strong></p> <p><img alt="data testing bayes" src=https://informatikalogi.com/wp-content/uploads/2017/04/contoh-kasus-4-naive-bayes-3.jpg></p> <p>Dimisalkan nilai komposisi <strong>male</strong> dan <strong>female</strong> adalah 50:50</p> <p><img alt="perhitungan bayes" src=https://informatikalogi.com/wp-content/uploads/2017/04/contoh-kasus-4-naive-bayes-5.jpg></p> <p><img alt="hasil perhitungan bayes" src=https://informatikalogi.com/wp-content/uploads/2017/04/contoh-kasus-4-naive-bayes-4.jpg></p> <p>Dengan demikian, data testing cenderung masuk ke kelas female karena memiliki angka lebih besar (5.3778*10-4) dibanding kelas male (6.1984*10-9).</p> <p>Berikut tugas perhitungan naive bayes menggunakan data iris bunga </p> <p>source code</p> <h4 id=tugas-naive-bayes-menggunakan-data-iris-bunga>Tugas naive bayes menggunakan data iris bunga<a class=headerlink href=#tugas-naive-bayes-menggunakan-data-iris-bunga title="Permanent link">&para;</a></h4> <p>import numpy as np import seaborn as sea import matplotlib.pyplot as mat from scipy import stats import pandas as calldata import math as rumus import statistics as s</p> <h4 id=membaca-data>Membaca data<a class=headerlink href=#membaca-data title="Permanent link">&para;</a></h4> <p>data = calldata.read_csv("data iris bunga tugas.csv")</p> <h1 id=printdatan-likelihood>print(data,"\n == Likelihood")<a class=headerlink href=#printdatan-likelihood title="Permanent link">&para;</a></h1> <h1 id=untuk-tabel-sepallength>untuk tabel sepallength<a class=headerlink href=#untuk-tabel-sepallength title="Permanent link">&para;</a></h1> <h1 id=mengelompokkan-data-class>mengelompokkan data class<a class=headerlink href=#mengelompokkan-data-class title="Permanent link">&para;</a></h1> <h1 id=senarai-untuk-collection-data>senarai untuk collection data<a class=headerlink href=#senarai-untuk-collection-data title="Permanent link">&para;</a></h1> <p>data_Iris = [] data_Iris_setosa=[] data_Iris_versicolor=[] data_Iris_virginica=[]</p> <h1 id=mengambil-data-dari-data-class>mengambil data dari data class<a class=headerlink href=#mengambil-data-dari-data-class title="Permanent link">&para;</a></h1> <p>for i in data['class']: data_Iris.append(i) if i == 'Iris-setosa': data_Iris_setosa.append(i) elif i == 'Iris-versicolor': data_Iris_versicolor.append(i) elif i == 'Iris-virginica': data_Iris_virginica.append(i)</p> <h1 id=jumlah-dari-yang-sudah-di-kumpulkan>jumlah dari yang sudah di kumpulkan<a class=headerlink href=#jumlah-dari-yang-sudah-di-kumpulkan title="Permanent link">&para;</a></h1> <p>jumlah_data_Iris = len(data_Iris) jumlah_Iris_setosa = len(data_Iris_setosa) jumlah_Iris_versicolor = len(data_Iris_versicolor) jumlah_Iris_virginica = len(data_Iris_virginica)</p> <h1 id=likelihood>likelihood<a class=headerlink href=#likelihood title="Permanent link">&para;</a></h1> <p>def sepallength_likelihood(i1,i2,i3,alldata): ​ <br> data4 = [] data5 = [] data6 = [] data7 = []</p> <div class=codehilite><pre><span></span>for i in data[&#39;sepallength&#39;]:

    if i &gt;= 4.0 and i &lt;= 4.9:
        data4.append(i)
    elif i &gt;=5.0 and i &lt;=5.9:
        data5.append(i)
    elif i &gt;=6.0 and i &lt;=6.9:
        data6.append(i)
    elif i &gt;=7.0 and i &lt;=7.9:
        data7.append(i)

#iris setosa
#P(c|x) = P(iris setosa| jangkauan 4 ) 
Pxc_data4_is = (len(data4)/i1)*(i1/alldata)/(len(data4)/alldata)
#P(c|x) = P(iris setosa| jangkauan 5 ) 
Pxc_data5_is= (len(data5)/i1)*(i1/alldata)/(len(data5)/alldata)
#P(c|x) = P(iris setosa| jangkauan 6 )
Pxc_data6_is= (len(data6)/i1)*(i1/alldata)/(len(data6)/alldata)
#P(c|x) = P(iris setosa| jangkauan 7 )
Pxc_data7_is= (len(data7)/i1)*(i1/alldata)/(len(data7)/alldata)

Iris_setosa = Pxc_data4_is*Pxc_data5_is*Pxc_data6_is*Pxc_data7_is

#iris versicolor
#P(c|x) = P(iris versicolor| jangkauan 4 ) 
Pxc_data4_iver= (len(data4)/i2)*(i2/alldata)/(len(data4)/alldata)
#P(c|x) = P(iris versicolor| jangkauan 5 ) 
Pxc_data5_iver= (len(data5)/i2)*(i2/alldata)/(len(data5)/alldata)
#P(c|x) = P(iris versicolor| jangkauan 6 )
Pxc_data6_iver= (len(data6)/i2)*(i2/alldata)/(len(data6)/alldata)
#P(c|x) = P(iris versicolor| jangkauan 7 )
Pxc_data7_iver= (len(data7)/i2)*(i2/alldata)/(len(data7)/alldata)

Iris_versicolor = Pxc_data4_iver*Pxc_data5_iver*Pxc_data6_iver*Pxc_data7_iver

#iris virginica
#P(c|x) = P(iris virginica| jangkauan 4 ) 
Pxc_data4_ivir= (len(data4)/i3)*(i3/alldata)/(len(data4)/alldata)

#P(c|x) = P(iris virginica| jangkauan 5 ) 
Pxc_data5_ivir= (len(data5)/i3)*(i3/alldata)/(len(data5)/alldata)
#P(c|x) = P(iris virginica| jangkauan 6 )
Pxc_data6_ivir= (len(data6)/i3)*(i3/alldata)/(len(data6)/alldata)
#P(c|x) = P(iris virginica| jangkauan 7 )
Pxc_data7_ivir= (len(data7)/i3)*(i3/alldata)/(len(data7)/alldata)

Iris_virginica = Pxc_data4_ivir*Pxc_data5_ivir*Pxc_data6_ivir*Pxc_data7_ivir
print (&quot;Sepallenght fitur \nIris setosa = &quot;,Iris_setosa,&quot;\nIris versicolor = &quot;,Iris_versicolor,&quot;\nIris virginica = &quot;,Iris_virginica)
</pre></div> <p>def sepalwidth_likelihood(i1,i2,i3,alldata): ​ <br> data2 = [] data3 = []</p> <div class=codehilite><pre><span></span>for i in data[&#39;sepalwidth&#39;]:

    if i &gt;= 2.0 and i &lt;= 2.9:
        data2.append(i)
    elif i &gt;=3.0 and i &lt;=3.9:
        data3.append(i)

#iris setosa
#P(c|x) = P(iris setosa| jangkauan 2 ) 
Pxc_data2_is = (len(data2)/i1)*(i1/alldata)/(len(data2)/alldata)
#P(c|x) = P(iris setosa| jangkauan 3 ) 
Pxc_data3_is= (len(data3)/i1)*(i1/alldata)/(len(data3)/alldata)

Iris_setosa = Pxc_data2_is*Pxc_data3_is

#iris versicolor
#P(c|x) = P(iris versicolor| jangkauan 2 ) 
Pxc_data2_iver= (len(data2)/i2)*(i2/alldata)/(len(data2)/alldata)
#P(c|x) = P(iris versicolor| jangkauan 3 ) 
Pxc_data3_iver= (len(data3)/i2)*(i2/alldata)/(len(data3)/alldata)

Iris_versicolor = Pxc_data2_iver*Pxc_data3_iver

#iris virginica
#P(c|x) = P(iris virginica| jangkauan 2 ) 
Pxc_data2_ivir= (len(data2)/i3)*(i3/alldata)/(len(data3)/alldata)
#P(c|x) = P(iris virginica| jangkauan 3 ) 
Pxc_data3_ivir= (len(data3)/i3)*(i3/alldata)/(len(data3)/alldata)

Iris_virginica = Pxc_data2_ivir*Pxc_data3_ivir

print (&quot;Sepalwidht fitur \nIris setosa = &quot;,Iris_setosa,&quot;\nIris versicolor = &quot;,Iris_versicolor,&quot;\nIris virginica = &quot;,Iris_virginica)
</pre></div> <p>def petallength_likelihood(i1,i2,i3,alldata): ​ <br> data2 = [] data3 = [] data4 = [] data5 = [] data6 = []</p> <div class=codehilite><pre><span></span>for i in data[&#39;petallength&#39;]:

    if i &gt;= 1.0 and i &lt;= 1.9:
        data2.append(i)
    elif i &gt;=3.0 and i &lt;=3.9:
        data3.append(i)
    elif i &gt;=4.0 and i &lt;=4.9:
        data4.append(i)
    elif i &gt;=5.0 and i &lt;=5.9:
        data5.append(i)
    elif i &gt;=6.0 and i &lt;=6.9:
        data6.append(i)

#iris setosa
#P(c|x) = P(iris setosa| jangkauan 2 ) 
Pxc_data2_is = (len(data2)/i1)*(i1/alldata)/(len(data2)/alldata)
#P(c|x) = P(iris setosa| jangkauan 3 ) 
Pxc_data3_is= (len(data3)/i1)*(i1/alldata)/(len(data3)/alldata)
#P(c|x) = P(iris setosa| jangkauan 4 ) 
Pxc_data4_is = (len(data4)/i1)*(i1/alldata)/(len(data4)/alldata)
#P(c|x) = P(iris setosa| jangkauan 5 ) 
Pxc_data5_is= (len(data5)/i1)*(i1/alldata)/(len(data5)/alldata)
#P(c|x) = P(iris setosa| jangkauan 6 ) 
Pxc_data6_is= (len(data6)/i1)*(i1/alldata)/(len(data6)/alldata)

Iris_setosa = Pxc_data2_is*Pxc_data3_is*Pxc_data4_is*Pxc_data5_is*Pxc_data6_is

#iris versicolor
#P(c|x) = P(iris versicolor| jangkauan 2 ) 
Pxc_data2_iver = (len(data2)/i2)*(i2/alldata)/(len(data2)/alldata)
#P(c|x) = P(iris versicolor| jangkauan 3 ) 
Pxc_data3_iver= (len(data3)/i2)*(i2/alldata)/(len(data3)/alldata)
#P(c|x) = P(iris versicolor| jangkauan 4 ) 
Pxc_data4_iver = (len(data4)/i2)*(i2/alldata)/(len(data4)/alldata)
#P(c|x) = P(iris versicolor| jangkauan 5 ) 
Pxc_data5_iver= (len(data5)/i2)*(i2/alldata)/(len(data5)/alldata)
#P(c|x) = P(iris versicolor jangkauan 6 ) 
Pxc_data6_iver= (len(data6)/i2)*(i2/alldata)/(len(data6)/alldata)

Iris_versicolor = Pxc_data2_iver*Pxc_data3_iver*Pxc_data4_iver*Pxc_data5_iver*Pxc_data6_iver

#iris virginica
#P(c|x) = P(iris virginica| jangkauan 2 )  
Pxc_data2_ivir = (len(data2)/i3)*(i3/alldata)/(len(data2)/alldata)
#P(c|x) = P(iris versicolor| jangkauan 3 ) 
Pxc_data3_ivir= (len(data3)/i3)*(i3/alldata)/(len(data3)/alldata)
#P(c|x) = P(iris versicolor| jangkauan 4 ) 
Pxc_data4_ivir = (len(data4)/i3)*(i3/alldata)/(len(data4)/alldata)
#P(c|x) = P(iris versicolor| jangkauan 5 ) 
Pxc_data5_ivir= (len(data5)/i3)*(i3/alldata)/(len(data5)/alldata)
#P(c|x) = P(iris versicolor jangkauan 6 ) 
Pxc_data6_ivir= (len(data6)/i3)*(i3/alldata)/(len(data6)/alldata)


Iris_virginica = Pxc_data2_ivir*Pxc_data3_ivir*Pxc_data4_ivir*Pxc_data5_ivir*Pxc_data6_ivir

print (&quot;Petallength fitur \nIris setosa = &quot;,Iris_setosa,&quot;\nIris versicolor = &quot;,Iris_versicolor,&quot;\nIris virginica = &quot;,Iris_virginica)
</pre></div> <h1 id=belum-revisi>belum revisi<a class=headerlink href=#belum-revisi title="Permanent link">&para;</a></h1> <p>def petalwidth_likelihood(i1,i2,i3,alldata): ​ <br> data0 = [] data1 = [] data2 = []</p> <div class=codehilite><pre><span></span>for i in data[&#39;petalwidth&#39;]:

    if i &gt;= 0.0 and i &lt;= 0.9:
        data0.append(i)
    elif i &gt;=1.0 and i &lt;=1.9:
        data1.append(i)
    elif i &gt;=2.0 and i &lt;=2.9:
        data2.append(i)
#iris setosa
#P(c|x) = P(iris setosa| jangkauan 0 ) 
Pxc_data0_is = (len(data0)/i1)*(i1/alldata)/(len(data0)/alldata)
#P(c|x) = P(iris setosa| jangkauan 1 ) 
Pxc_data1_is= (len(data1)/i1)*(i1/alldata)/(len(data1)/alldata)
#P(c|x) = P(iris setosa| jangkauan 2 ) 
Pxc_data2_is= (len(data2)/i1)*(i1/alldata)/(len(data2)/alldata)

Iris_setosa = Pxc_data0_is*Pxc_data1_is*Pxc_data2_is

#iris versicolor
#P(c|x) = P(iris versicolor| jangkauan 0 ) 
Pxc_data0_iver = (len(data0)/i2)*(i2/alldata)/(len(data0)/alldata)
#P(c|x) = P(iris versicolor| jangkauan 1 ) 
Pxc_data1_iver= (len(data1)/i2)*(i2/alldata)/(len(data1)/alldata)
#P(c|x) = P(iris versicolor| jangkauan 2 ) 
Pxc_data2_iver= (len(data2)/i2)*(i2/alldata)/(len(data2)/alldata)

Iris_versicolor = Pxc_data0_iver*Pxc_data1_iver*Pxc_data2_iver

#iris virginica
#P(c|x) = P(iris virginica| jangkauan 0 ) 
Pxc_data0_ivir= (len(data0)/i3)*(i3/alldata)/(len(data0)/alldata)
#P(c|x) = P(iris virginica| jangkauan 1 ) 
Pxc_data1_ivir= (len(data1)/i3)*(i3/alldata)/(len(data1)/alldata)
#P(c|x) = P(iris virginica| jangkauan 2 ) 
Pxc_data2_ivir= (len(data2)/i3)*(i3/alldata)/(len(data2)/alldata)

Iris_virginica = Pxc_data0_ivir*Pxc_data1_ivir*Pxc_data2_ivir

print (&quot;Sepalwidht fitur \nIris setosa = &quot;,Iris_setosa,&quot;\nIris versicolor = &quot;,Iris_versicolor,&quot;\nIris virginica = &quot;,Iris_virginica)
</pre></div> <h1 id=memanggil-fungsi>memanggil fungsi<a class=headerlink href=#memanggil-fungsi title="Permanent link">&para;</a></h1> <p>sepallength_likelihood(jumlah_Iris_setosa,jumlah_Iris_versicolor,jumlah_Iris_virginica,jumlah_data_Iris) sepalwidth_likelihood(jumlah_Iris_setosa,jumlah_Iris_versicolor,jumlah_Iris_virginica,jumlah_data_Iris) petallength_likelihood(jumlah_Iris_setosa,jumlah_Iris_versicolor,jumlah_Iris_virginica,jumlah_data_Iris) petalwidth_likelihood(jumlah_Iris_setosa,jumlah_Iris_versicolor,jumlah_Iris_virginica,jumlah_data_Iris)</p> <p>print(" Numerical Predictor \n:")</p> <p>def sepallength_num(i1,i2,i3,alldata): data_class=[] data_sepallength=[]</p> <div class=codehilite><pre><span></span>sepallength_is=[]
sepallength_ver=[]
sepallength_vir=[]

for c in data[&#39;class&#39;]:
    data_class.append(c)

for i in data[&#39;sepallength&#39;]:
    data_sepallength.append(i)

for j in range(len(data_class)):
    if data_class [j] == &#39;Iris-setosa&#39;:
        sepallength_is.append(data_sepallength[j])
    if data_class [j] == &#39;Iris-versicolor&#39;:
        sepallength_ver.append(data_sepallength[j])
    if data_class [j] == &#39;Iris-virginica&#39;:
        sepallength_vir.append(data_sepallength[j])

normal_dis_is = (1/(rumus.sqrt((2*rumus.pi))*s.stdev(sepallength_is)))-(rumus.pow((7.6-(s.mean(sepallength_is))),2)/(2*pow(s.stdev(sepallength_is),2)))
print(&quot;P(sepallenght = 7.6|class = Iris-setosa) = &quot;,normal_dis_is)

normal_dis_ver = (1/(rumus.sqrt((2*rumus.pi))*s.stdev(sepallength_ver)))-(rumus.pow((7.6-(s.mean(sepallength_ver))),2)/(2*pow(s.stdev(sepallength_ver),2)))
print(&quot;P(sepallenght = 7.6|class = Iris-versicolor) = &quot;,normal_dis_ver)

normal_dis_vir = (1/(rumus.sqrt((2*rumus.pi))*s.stdev(sepallength_vir)))-(rumus.pow((7.6-(s.mean(sepallength_vir))),2)/(2*pow(s.stdev(sepallength_vir),2)))
print(&quot;P(sepallenght = 7.6|class = Iris-virginica) = &quot;,normal_dis_vir)
</pre></div> <p>def sepalwidth_num(i1,i2,i3,alldata): data_class=[] data_sepalwidth=[]</p> <div class=codehilite><pre><span></span>sepalwidth_is=[]
sepalwidth_ver=[]
sepalwidth_vir=[]

for c in data[&#39;class&#39;]:
    data_class.append(c)

for i in data[&#39;sepalwidth&#39;]:
    data_sepalwidth.append(i)

for j in range(len(data_class)):
    if data_class [j] == &#39;Iris-setosa&#39;:
        sepalwidth_is.append(data_sepalwidth[j])
    if data_class [j] == &#39;Iris-versicolor&#39;:
        sepalwidth_ver.append(data_sepalwidth[j])
    if data_class [j] == &#39;Iris-virginica&#39;:
        sepalwidth_vir.append(data_sepalwidth[j])

normal_dis_is = (1/(rumus.sqrt((2*rumus.pi))*s.stdev(sepalwidth_is)))-(rumus.pow((3.9-(s.mean(sepalwidth_is))),2)/(2*pow(s.stdev(sepalwidth_is),2)))
print(&quot;P(sepalwidth = 3.9|class = Iris-setosa) = &quot;,normal_dis_is)

normal_dis_ver = (1/(rumus.sqrt((2*rumus.pi))*s.stdev(sepalwidth_ver)))-(rumus.pow((3.9-(s.mean(sepalwidth_ver))),2)/(2*pow(s.stdev(sepalwidth_ver),2)))
print(&quot;P(sepalwidth = 3.9|class = Iris-versicolor) = &quot;,normal_dis_ver)

normal_dis_vir = (1/(rumus.sqrt((2*rumus.pi))*s.stdev(sepalwidth_vir)))-(rumus.pow((3.9-(s.mean(sepalwidth_vir))),2)/(2*pow(s.stdev(sepalwidth_vir),2)))
print(&quot;P(sepalwidth = 3.9|class = Iris-virginica) = &quot;,normal_dis_vir)
</pre></div> <p>def petallength_num(i1,i2,i3,alldata): data_class=[] data_petallength=[]</p> <div class=codehilite><pre><span></span>petallength_is=[]
petallength_ver=[]
petallength_vir=[]

for c in data[&#39;class&#39;]:
    data_class.append(c)

for i in data[&#39;petallength&#39;]:
    data_petallength.append(i)

for j in range(len(data_class)):
    if data_class [j] == &#39;Iris-setosa&#39;:
        petallength_is.append(data_petallength[j])
    if data_class [j] == &#39;Iris-versicolor&#39;:
        petallength_ver.append(data_petallength[j])
    if data_class [j] == &#39;Iris-virginica&#39;:
        petallength_vir.append(data_petallength[j])

normal_dis_is = (1/(rumus.sqrt((2*rumus.pi))*s.stdev(petallength_is)))-(rumus.pow((6.3-(s.mean(petallength_is))),2)/(2*pow(s.stdev(petallength_is),2)))
print(&quot;P(petallength = 6.3|class = Iris-setosa) = &quot;,normal_dis_is)

normal_dis_ver = (1/(rumus.sqrt((2*rumus.pi))*s.stdev(petallength_ver)))-(rumus.pow((6.3-(s.mean(petallength_ver))),2)/(2*pow(s.stdev(petallength_ver),2)))
print(&quot;P(petallength = 6.3|class = Iris-versicolor) = &quot;,normal_dis_ver)

normal_dis_vir = (1/(rumus.sqrt((2*rumus.pi))*s.stdev(petallength_vir)))-(rumus.pow((6.3-(s.mean(petallength_vir))),2)/(2*pow(s.stdev(petallength_vir),2)))
print(&quot;P(petallength = 6.3|class = Iris-virginica) = &quot;,normal_dis_vir)
</pre></div> <p>def petalwidth_num(i1,i2,i3,alldata): data_class=[] data_petalwidth=[]</p> <div class=codehilite><pre><span></span>petalwidth_is=[]
petalwidth_ver=[]
petalwidth_vir=[]

for c in data[&#39;class&#39;]:
    data_class.append(c)

for i in data[&#39;petalwidth&#39;]:
    data_petalwidth.append(i)

for j in range(len(data_class)):
    if data_class [j] == &#39;Iris-setosa&#39;:
        petalwidth_is.append(data_petalwidth[j])
    if data_class [j] == &#39;Iris-versicolor&#39;:
        petalwidth_ver.append(data_petalwidth[j])
    if data_class [j] == &#39;Iris-virginica&#39;:
        petalwidth_vir.append(data_petalwidth[j])

normal_dis_is = (1/(rumus.sqrt((2*rumus.pi))*s.stdev(petalwidth_is)))-(rumus.pow((6.3-(s.mean(petalwidth_is))),2)/(2*pow(s.stdev(petalwidth_is),2)))
print(&quot;P(petalwidth = 6.3|class = Iris-setosa) = &quot;,normal_dis_is)

normal_dis_ver = (1/(rumus.sqrt((2*rumus.pi))*s.stdev(petalwidth_ver)))-(rumus.pow((6.3-(s.mean(petalwidth_ver))),2)/(2*pow(s.stdev(petalwidth_ver),2)))
print(&quot;P(petalwidth = 6.3|class = Iris-versicolor) = &quot;,normal_dis_ver)

normal_dis_vir = (1/(rumus.sqrt((2*rumus.pi))*s.stdev(petalwidth_vir)))-(rumus.pow((6.3-(s.mean(petalwidth_vir))),2)/(2*pow(s.stdev(petalwidth_vir),2)))
print(&quot;P(petalwidth = 6.3|class = Iris-virginica) = &quot;,normal_dis_vir)
</pre></div> <h4 id=menjalankan-fungsi-fitur>menjalankan fungsi fitur<a class=headerlink href=#menjalankan-fungsi-fitur title="Permanent link">&para;</a></h4> <p>print("Sepallength naive bayes") sepallength_num(jumlah_Iris_setosa,jumlah_Iris_versicolor,jumlah_Iris_virginica,jumlah_data_Iris) print("Sepalwidth naive bayes") sepalwidth_num(jumlah_Iris_setosa,jumlah_Iris_versicolor,jumlah_Iris_virginica,jumlah_data_Iris) print("Petallength naive bayes") petallength_num(jumlah_Iris_setosa,jumlah_Iris_versicolor,jumlah_Iris_virginica,jumlah_data_Iris) print("Petallength naive bayes") petalwidth_num(jumlah_Iris_setosa,jumlah_Iris_versicolor,jumlah_Iris_virginica,jumlah_data_Iris)</p> </article> </div> </div> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> Copyright &copy; 2016 - 2019 Martin Donath </div> powered by <a href=https://www.mkdocs.org>MkDocs</a> and <a href=https://squidfunk.github.io/mkdocs-material/ > Material for MkDocs</a> </div> <div class=md-footer-social> <link rel=stylesheet href=../assets/fonts/font-awesome.css> <a href=http://struct.cc class="md-footer-social__link fa fa-globe"></a> <a href=https://github.com/squidfunk class="md-footer-social__link fa fa-github-alt"></a> <a href=https://twitter.com/squidfunk class="md-footer-social__link fa fa-twitter"></a> <a href=https://linkedin.com/in/squidfunk class="md-footer-social__link fa fa-linkedin"></a> </div> </div> </div> </footer> </div> <script src=../assets/javascripts/application.718059d6.js></script> <script>app.initialize({version:"1.0.4",url:{base:".."}})</script> </body> </html>